{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LM Format Enforcer Integration with llama.cpp (python bindings)\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/noamgat/lm-format-enforcer/blob/main/samples/colab_llamacpppython_integration.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "This notebook shows how you can integrate with the llama.cpp library via its [python bindings](https://github.com/abetlen/llama-cpp-python). We will do this using its ```LogitsProcessor``` interface, and show how we integrate with ~30 lines of code for the connection.\n",
    "\n",
    "This sample notebook focuses on simplicity and ease of setup. Therefore we will use a CPU version of llamacpp, which will make inference slower. For production use, you should use the GPU version of llamacpp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing dependencies\n",
    "\n",
    "We begin by installing the dependencies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-cpp-python lm-format-enforcer huggingface-hub pandas numpy\n",
    "\n",
    "# When running from source / developing the library, use this instead\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# import sys\n",
    "# import os\n",
    "# sys.path.append(os.path.abspath('..'))\n",
    "## os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model\n",
    "\n",
    "This demo uses [Llama2 gguf weights by TheBloke](https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF). We will use huggingface hub to download the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noamgat/mambaforge/envs/llamacpppy/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /home/noamgat/huggingface/hub/models--TheBloke--Llama-2-7b-Chat-GGUF/snapshots/191239b3e26b2882fb562ffccdd1cf0f65402adb/llama-2-7b-chat.Q5_K_M.gguf (version GGUF V2 (latest))\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "from huggingface_hub import hf_hub_download\n",
    "downloaded_model_path = hf_hub_download(repo_id=\"TheBloke/Llama-2-7b-Chat-GGUF\", filename=\"llama-2-7b-chat.Q5_K_M.gguf\")\n",
    "llm = Llama(model_path=downloaded_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the previous cell executed successfully, you have propertly set up your Colab runtime and loaded the llama.cpp model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few helper functions to make display nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_header(text):\n",
    "    display(Markdown(f'**{text}**'))\n",
    "\n",
    "def display_content(text):\n",
    "    display(Markdown(f'```\\n{text}\\n```'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the prompt for the specific language model\n",
    "\n",
    "We set up the prompting style according to the [Llama2 demo](https://huggingface.co/spaces/huggingface-projects/llama-2-13b-chat/blob/main/app.py). We simplify the implementation a bit as we don't need chat history for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\\n",
    "\"\"\"\n",
    "\n",
    "def get_prompt(message: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT) -> str:\n",
    "    return f'<s>[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n{message} [/INST]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating text with the LM Format Enforcer Logits Processor\n",
    "\n",
    "llama.cpp's python bindigs have a ```LogitsProcessor``` interface similar to one that exists in Huggingface Transformers. We will connect to this API and set the logits that are not allowed to negative infinity, ensuring they are not selected.\n",
    "\n",
    "We use the high level llama.cpp python interface to create a ```TokenEnforcer```, and a ```LogitsProcessor``` that uses it.\n",
    "The integration can be found in [lmformatenforcer/integrations/llamacpp.py](https://github.com/noamgat/lm-format-enforcer/blob/main/lmformatenforcer/integrations/llamacpp.py).\n",
    "\n",
    "In order to integrate our logits processor with LlamaCpp, we create a ```LogitsProcessorList``` and pass it as a keyword variable when using the ```Llama``` class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from llama_cpp import LogitsProcessorList\n",
    "from lmformatenforcer import CharacterLevelParser\n",
    "from lmformatenforcer.integrations.llamacpp import build_llamacpp_logits_processor, build_token_enforcer_tokenizer_data\n",
    "\n",
    "tokenizer_data = build_token_enforcer_tokenizer_data(llm)\n",
    "\n",
    "def llamacpp_with_character_level_parser(prompt: str, character_level_parser: Optional[CharacterLevelParser]) -> str:\n",
    "    logits_processors: Optional[LogitsProcessorList] = None\n",
    "    if character_level_parser:\n",
    "        logits_processors = LogitsProcessorList([build_llamacpp_logits_processor(tokenizer_data, character_level_parser)])\n",
    "    \n",
    "    output = llm(prompt, logits_processor=logits_processors, max_tokens=100)\n",
    "    text: str = output['choices'][0]['text']\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LlamaCpp + JSON Use case\n",
    "\n",
    "Now we demonstrate using ```JsonSchemaParser```. We create a pydantic model, generate the schema from it, and use that to enforce the format.\n",
    "The output will always be in a format that can be parsed by the parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_395615/2888867492.py:13: PydanticDeprecatedSince20: The `schema_json` method is deprecated; use `model_json_schema` and json.dumps instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.4/migration/\n",
      "  question_with_schema = f'{question}{AnswerFormat.schema_json()}'\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "<s>[INST] <<SYS>>\n",
       "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
       "\n",
       "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
       "<</SYS>>\n",
       "\n",
       "Please give me information about Michael Jordan. You MUST answer using the following json schema: {\"properties\": {\"first_name\": {\"title\": \"First Name\", \"type\": \"string\"}, \"last_name\": {\"title\": \"Last Name\", \"type\": \"string\"}, \"year_of_birth\": {\"title\": \"Year Of Birth\", \"type\": \"integer\"}, \"num_seasons_in_nba\": {\"title\": \"Num Seasons In Nba\", \"type\": \"integer\"}}, \"required\": [\"first_name\", \"last_name\", \"year_of_birth\", \"num_seasons_in_nba\"], \"title\": \"AnswerFormat\", \"type\": \"object\"} [/INST]\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer, Without json schema enforcing:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time = 16719.92 ms\n",
      "llama_print_timings:      sample time =    43.66 ms /   128 runs   (    0.34 ms per token,  2931.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11262.72 ms /   128 runs   (   87.99 ms per token,    11.36 tokens per second)\n",
      "llama_print_timings:       total time = 11447.94 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "  Of course! I'd be happy to provide information about Michael Jordan in a safe and respectful manner. Here is the answer in the format requested:\n",
       "{\n",
       "\"first_name\": \"Michael\",\n",
       "\"last_name\": \"Jordan\",\n",
       "\"year_of_birth\": 1963,\n",
       "\"num_seasons_in_nba\": 15\n",
       "}\n",
       "Here are some key facts about Michael Jordan:\n",
       "* First Name: Michael\n",
       "* Last Name: Jordan\n",
       "* Year of Birth: 1963\n",
       "* Number of Seasons in the\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer, With json schema enforcing:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_395615/2888867492.py:24: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.4/migration/\n",
      "  result = llamacpp_with_character_level_parser(llm, prompt, JsonSchemaParser(AnswerFormat.schema()))\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time = 16760.31 ms\n",
      "llama_print_timings:      sample time =    18.00 ms /    55 runs   (    0.33 ms per token,  3055.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5362.52 ms /    55 runs   (   97.50 ms per token,    10.26 tokens per second)\n",
      "llama_print_timings:       total time =  5582.66 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "  {\n",
       "\"first_name\": \"Michael\",\n",
       "\"last_name\": \"Jordan\",\n",
       "\"year_of_birth\": 1963,\n",
       "\"num_seasons_in_nba\": 15 }\n",
       "\n",
       "\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer, With json mode (json output, no specific schema) enforcing:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time = 16719.92 ms\n",
      "llama_print_timings:      sample time =    42.56 ms /   128 runs   (    0.33 ms per token,  3007.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11260.41 ms /   128 runs   (   87.97 ms per token,    11.37 tokens per second)\n",
      "llama_print_timings:       total time = 11722.26 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "  {\n",
       "\"properties\": {\n",
       "\"first_name\": {\"title\": \"First Name\", \"type\": \"string\"},\n",
       "\"last_name\": {\"title\": \"Last Name\", \"type\": \"string\"},\n",
       "\"year_of_birth\": {\"title\": \"Year Of Birth\", \"type\": \"integer\"},\n",
       "\"num_seasons_in_nba\": {\"title\": \"Num Seasons In Nba\", \"type\": \"integer\"}\n",
       "},\n",
       "\"required\": [\"first_name\", \"last_name\", \"year_of_birth\", \"num_seasons_\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lmformatenforcer import JsonSchemaParser\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from typing import List\n",
    "\n",
    "class AnswerFormat(BaseModel):\n",
    "    first_name: str\n",
    "    last_name: str\n",
    "    year_of_birth: int\n",
    "    num_seasons_in_nba: int\n",
    "\n",
    "question = 'Please give me information about Michael Jordan. You MUST answer using the following json schema: '\n",
    "question_with_schema = f'{question}{AnswerFormat.schema_json()}'\n",
    "prompt = get_prompt(question_with_schema)\n",
    "\n",
    "display_header(\"Prompt:\")\n",
    "display_content(prompt)\n",
    "\n",
    "display_header(\"Answer, Without json schema enforcing:\")\n",
    "result = llamacpp_with_character_level_parser(prompt, None)\n",
    "display_content(result)\n",
    "\n",
    "display_header(\"Answer, With json schema enforcing:\")\n",
    "result = llamacpp_with_character_level_parser(prompt, JsonSchemaParser(AnswerFormat.schema()))\n",
    "display_content(result)\n",
    "\n",
    "display_header(\"Answer, With json mode (json output, no specific schema) enforcing:\")\n",
    "result = llamacpp_with_character_level_parser(prompt, JsonSchemaParser(None))\n",
    "display_content(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the enforced output matches the required schema, while the unenforced does not. We have successfully integrated with llama.cpp!\n",
    "\n",
    "Note - the last cell probably took quite a long time to run. This is due to this notebook using CPU inference. LM Format Enforcer's runtime footprint is negligible compared to the model's runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the impact of the format enforcer\n",
    "\n",
    "There is an API to analyze the impact of the format enforcer on the model's output. We will use it to see how many tokens were changed by the format enforcer.\n",
    "\n",
    "The `analyze=True` parameter to `build_llamacpp_logits_processor()` causes the returning object to have an analyzer property, that we can get a report dictionary from after the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_395615/4231260298.py:3: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.4/migration/\n",
      "  parser = JsonSchemaParser(AnswerFormat.schema())\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "<s>[INST] <<SYS>>\n",
       "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
       "\n",
       "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
       "<</SYS>>\n",
       "\n",
       "Please give me information about Michael Jordan. You MUST answer using the following json schema: {\"properties\": {\"first_name\": {\"title\": \"First Name\", \"type\": \"string\"}, \"last_name\": {\"title\": \"Last Name\", \"type\": \"string\"}, \"year_of_birth\": {\"title\": \"Year Of Birth\", \"type\": \"integer\"}, \"num_seasons_in_nba\": {\"title\": \"Num Seasons In Nba\", \"type\": \"integer\"}}, \"required\": [\"first_name\", \"last_name\", \"year_of_birth\", \"num_seasons_in_nba\"], \"title\": \"AnswerFormat\", \"type\": \"object\"} [/INST]\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time = 16760.31 ms\n",
      "llama_print_timings:      sample time =    17.89 ms /    55 runs   (    0.33 ms per token,  3074.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5362.62 ms /    55 runs   (   97.50 ms per token,    10.26 tokens per second)\n",
      "llama_print_timings:       total time =  5685.62 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "  {\n",
       "\"first_name\": \"Michael\",\n",
       "\"last_name\": \"Jordan\",\n",
       "\"year_of_birth\": 1963,\n",
       "\"num_seasons_in_nba\": 15\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generated_token</th>\n",
       "      <th>generated_token_idx</th>\n",
       "      <th>generated_score</th>\n",
       "      <th>leading_token</th>\n",
       "      <th>leading_token_idx</th>\n",
       "      <th>leading_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>29871</td>\n",
       "      <td>0.99998</td>\n",
       "      <td></td>\n",
       "      <td>29871</td>\n",
       "      <td>0.99998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{</td>\n",
       "      <td>426</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>Of</td>\n",
       "      <td>4587</td>\n",
       "      <td>0.90464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n</td>\n",
       "      <td>13</td>\n",
       "      <td>0.99852</td>\n",
       "      <td>\\n</td>\n",
       "      <td>13</td>\n",
       "      <td>0.99852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"</td>\n",
       "      <td>29908</td>\n",
       "      <td>0.98000</td>\n",
       "      <td>\"</td>\n",
       "      <td>29908</td>\n",
       "      <td>0.98000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first</td>\n",
       "      <td>4102</td>\n",
       "      <td>0.35435</td>\n",
       "      <td>first</td>\n",
       "      <td>4102</td>\n",
       "      <td>0.35435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_</td>\n",
       "      <td>29918</td>\n",
       "      <td>0.99989</td>\n",
       "      <td>_</td>\n",
       "      <td>29918</td>\n",
       "      <td>0.99989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>name</td>\n",
       "      <td>978</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>name</td>\n",
       "      <td>978</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\":</td>\n",
       "      <td>1115</td>\n",
       "      <td>0.99993</td>\n",
       "      <td>\":</td>\n",
       "      <td>1115</td>\n",
       "      <td>0.99993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"</td>\n",
       "      <td>376</td>\n",
       "      <td>0.99887</td>\n",
       "      <td>\"</td>\n",
       "      <td>376</td>\n",
       "      <td>0.99887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Michael</td>\n",
       "      <td>24083</td>\n",
       "      <td>0.97372</td>\n",
       "      <td>Michael</td>\n",
       "      <td>24083</td>\n",
       "      <td>0.97372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\",</td>\n",
       "      <td>613</td>\n",
       "      <td>0.98418</td>\n",
       "      <td>\",</td>\n",
       "      <td>613</td>\n",
       "      <td>0.98418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\n</td>\n",
       "      <td>13</td>\n",
       "      <td>0.99981</td>\n",
       "      <td>\\n</td>\n",
       "      <td>13</td>\n",
       "      <td>0.99981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"</td>\n",
       "      <td>29908</td>\n",
       "      <td>0.99928</td>\n",
       "      <td>\"</td>\n",
       "      <td>29908</td>\n",
       "      <td>0.99928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>last</td>\n",
       "      <td>4230</td>\n",
       "      <td>0.99998</td>\n",
       "      <td>last</td>\n",
       "      <td>4230</td>\n",
       "      <td>0.99998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>_</td>\n",
       "      <td>29918</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>_</td>\n",
       "      <td>29918</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>name</td>\n",
       "      <td>978</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>name</td>\n",
       "      <td>978</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\":</td>\n",
       "      <td>1115</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>\":</td>\n",
       "      <td>1115</td>\n",
       "      <td>0.99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"</td>\n",
       "      <td>376</td>\n",
       "      <td>0.99994</td>\n",
       "      <td>\"</td>\n",
       "      <td>376</td>\n",
       "      <td>0.99994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>J</td>\n",
       "      <td>29967</td>\n",
       "      <td>0.99989</td>\n",
       "      <td>J</td>\n",
       "      <td>29967</td>\n",
       "      <td>0.99989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ord</td>\n",
       "      <td>536</td>\n",
       "      <td>0.99996</td>\n",
       "      <td>ord</td>\n",
       "      <td>536</td>\n",
       "      <td>0.99996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>an</td>\n",
       "      <td>273</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>an</td>\n",
       "      <td>273</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\",</td>\n",
       "      <td>613</td>\n",
       "      <td>0.99998</td>\n",
       "      <td>\",</td>\n",
       "      <td>613</td>\n",
       "      <td>0.99998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\\n</td>\n",
       "      <td>13</td>\n",
       "      <td>0.99964</td>\n",
       "      <td>\\n</td>\n",
       "      <td>13</td>\n",
       "      <td>0.99964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"</td>\n",
       "      <td>29908</td>\n",
       "      <td>0.99963</td>\n",
       "      <td>\"</td>\n",
       "      <td>29908</td>\n",
       "      <td>0.99963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>year</td>\n",
       "      <td>6360</td>\n",
       "      <td>0.99992</td>\n",
       "      <td>year</td>\n",
       "      <td>6360</td>\n",
       "      <td>0.99992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>_</td>\n",
       "      <td>29918</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>_</td>\n",
       "      <td>29918</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>of</td>\n",
       "      <td>974</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>of</td>\n",
       "      <td>974</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>_</td>\n",
       "      <td>29918</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>_</td>\n",
       "      <td>29918</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>b</td>\n",
       "      <td>29890</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "      <td>29890</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>irth</td>\n",
       "      <td>7515</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>irth</td>\n",
       "      <td>7515</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>\":</td>\n",
       "      <td>1115</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>\":</td>\n",
       "      <td>1115</td>\n",
       "      <td>0.99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td>29871</td>\n",
       "      <td>0.99973</td>\n",
       "      <td></td>\n",
       "      <td>29871</td>\n",
       "      <td>0.99973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>29896</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>29896</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9</td>\n",
       "      <td>29929</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>9</td>\n",
       "      <td>29929</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6</td>\n",
       "      <td>29953</td>\n",
       "      <td>0.99988</td>\n",
       "      <td>6</td>\n",
       "      <td>29953</td>\n",
       "      <td>0.99988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>29941</td>\n",
       "      <td>0.99978</td>\n",
       "      <td>3</td>\n",
       "      <td>29941</td>\n",
       "      <td>0.99978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>,</td>\n",
       "      <td>29892</td>\n",
       "      <td>0.99998</td>\n",
       "      <td>,</td>\n",
       "      <td>29892</td>\n",
       "      <td>0.99998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>\\n</td>\n",
       "      <td>13</td>\n",
       "      <td>0.99836</td>\n",
       "      <td>\\n</td>\n",
       "      <td>13</td>\n",
       "      <td>0.99836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>\"</td>\n",
       "      <td>29908</td>\n",
       "      <td>0.99975</td>\n",
       "      <td>\"</td>\n",
       "      <td>29908</td>\n",
       "      <td>0.99975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>num</td>\n",
       "      <td>1949</td>\n",
       "      <td>0.99986</td>\n",
       "      <td>num</td>\n",
       "      <td>1949</td>\n",
       "      <td>0.99986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>_</td>\n",
       "      <td>29918</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>_</td>\n",
       "      <td>29918</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>se</td>\n",
       "      <td>344</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>se</td>\n",
       "      <td>344</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>asons</td>\n",
       "      <td>7040</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>asons</td>\n",
       "      <td>7040</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>_</td>\n",
       "      <td>29918</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>_</td>\n",
       "      <td>29918</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>in</td>\n",
       "      <td>262</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>in</td>\n",
       "      <td>262</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>_</td>\n",
       "      <td>29918</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>_</td>\n",
       "      <td>29918</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>n</td>\n",
       "      <td>29876</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>n</td>\n",
       "      <td>29876</td>\n",
       "      <td>0.99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ba</td>\n",
       "      <td>2291</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>ba</td>\n",
       "      <td>2291</td>\n",
       "      <td>0.99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>\":</td>\n",
       "      <td>1115</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>\":</td>\n",
       "      <td>1115</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td></td>\n",
       "      <td>29871</td>\n",
       "      <td>0.99999</td>\n",
       "      <td></td>\n",
       "      <td>29871</td>\n",
       "      <td>0.99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>29896</td>\n",
       "      <td>0.99796</td>\n",
       "      <td>1</td>\n",
       "      <td>29896</td>\n",
       "      <td>0.99796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5</td>\n",
       "      <td>29945</td>\n",
       "      <td>0.97345</td>\n",
       "      <td>5</td>\n",
       "      <td>29945</td>\n",
       "      <td>0.97345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>\\n</td>\n",
       "      <td>13</td>\n",
       "      <td>0.93929</td>\n",
       "      <td>\\n</td>\n",
       "      <td>13</td>\n",
       "      <td>0.93929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>\\n</td>\n",
       "      <td>13</td>\n",
       "      <td>0.61954</td>\n",
       "      <td>\\n</td>\n",
       "      <td>13</td>\n",
       "      <td>0.61954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   generated_token  generated_token_idx  generated_score leading_token  leading_token_idx  leading_score\n",
       "0                                 29871          0.99998                            29871        0.99998\n",
       "1                {                  426          0.00006            Of               4587        0.90464\n",
       "2               \\n                   13          0.99852            \\n                 13        0.99852\n",
       "3                \"                29908          0.98000             \"              29908        0.98000\n",
       "4            first                 4102          0.35435         first               4102        0.35435\n",
       "5                _                29918          0.99989             _              29918        0.99989\n",
       "6             name                  978          1.00000          name                978        1.00000\n",
       "7               \":                 1115          0.99993            \":               1115        0.99993\n",
       "8                \"                  376          0.99887             \"                376        0.99887\n",
       "9          Michael                24083          0.97372       Michael              24083        0.97372\n",
       "10              \",                  613          0.98418            \",                613        0.98418\n",
       "11              \\n                   13          0.99981            \\n                 13        0.99981\n",
       "12               \"                29908          0.99928             \"              29908        0.99928\n",
       "13            last                 4230          0.99998          last               4230        0.99998\n",
       "14               _                29918          1.00000             _              29918        1.00000\n",
       "15            name                  978          1.00000          name                978        1.00000\n",
       "16              \":                 1115          0.99999            \":               1115        0.99999\n",
       "17               \"                  376          0.99994             \"                376        0.99994\n",
       "18               J                29967          0.99989             J              29967        0.99989\n",
       "19             ord                  536          0.99996           ord                536        0.99996\n",
       "20              an                  273          1.00000            an                273        1.00000\n",
       "21              \",                  613          0.99998            \",                613        0.99998\n",
       "22              \\n                   13          0.99964            \\n                 13        0.99964\n",
       "23               \"                29908          0.99963             \"              29908        0.99963\n",
       "24            year                 6360          0.99992          year               6360        0.99992\n",
       "25               _                29918          1.00000             _              29918        1.00000\n",
       "26              of                  974          1.00000            of                974        1.00000\n",
       "27               _                29918          1.00000             _              29918        1.00000\n",
       "28               b                29890          1.00000             b              29890        1.00000\n",
       "29            irth                 7515          1.00000          irth               7515        1.00000\n",
       "30              \":                 1115          0.99999            \":               1115        0.99999\n",
       "31                                29871          0.99973                            29871        0.99973\n",
       "32               1                29896          1.00000             1              29896        1.00000\n",
       "33               9                29929          1.00000             9              29929        1.00000\n",
       "34               6                29953          0.99988             6              29953        0.99988\n",
       "35               3                29941          0.99978             3              29941        0.99978\n",
       "36               ,                29892          0.99998             ,              29892        0.99998\n",
       "37              \\n                   13          0.99836            \\n                 13        0.99836\n",
       "38               \"                29908          0.99975             \"              29908        0.99975\n",
       "39             num                 1949          0.99986           num               1949        0.99986\n",
       "40               _                29918          1.00000             _              29918        1.00000\n",
       "41              se                  344          1.00000            se                344        1.00000\n",
       "42           asons                 7040          1.00000         asons               7040        1.00000\n",
       "43               _                29918          1.00000             _              29918        1.00000\n",
       "44              in                  262          1.00000            in                262        1.00000\n",
       "45               _                29918          1.00000             _              29918        1.00000\n",
       "46               n                29876          0.99999             n              29876        0.99999\n",
       "47              ba                 2291          0.99999            ba               2291        0.99999\n",
       "48              \":                 1115          1.00000            \":               1115        1.00000\n",
       "49                                29871          0.99999                            29871        0.99999\n",
       "50               1                29896          0.99796             1              29896        0.99796\n",
       "51               5                29945          0.97345             5              29945        0.97345\n",
       "52              \\n                   13          0.93929            \\n                 13        0.93929\n",
       "53              \\n                   13          0.61954            \\n                 13        0.61954"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "parser = JsonSchemaParser(AnswerFormat.schema())\n",
    "# Note the analyze=True flag, which is required to collect the information for the analysis later.\n",
    "logits_processors = LogitsProcessorList([build_llamacpp_logits_processor(llm, parser, analyze=True)])\n",
    "\n",
    "display_header(\"Prompt:\")\n",
    "display_content(prompt)\n",
    "\n",
    "display_header(\"Answer:\")\n",
    "output = llm(prompt, logits_processor=logits_processors)\n",
    "text: str = output['choices'][0]['text']\n",
    "display_content(text)\n",
    "\n",
    "output_tokens = list(llm.eval_tokens)\n",
    "# These two lines are possible because of the analyze=True flag above\n",
    "analyzer = logits_processors[0].analyzer\n",
    "report = analyzer.generate_report_dict(output_tokens)\n",
    "\n",
    "enforced_scores = pd.DataFrame(report)\n",
    "# Setting some display options to make the table more readable\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.float_format', ' {:,.5f}'.format)\n",
    "display(enforced_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interesting timestep is timestep 1, where we see the format enforcer forced the `{` character. Other than that, the model was able to correctly generate in-format JSON on its own. The LM Format Enforcer did not have to intervene, and due to its support of letting the model control whitespaces, it generated the JSON format that the LLM knows best, without explicit knowledge of it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmformatenforcer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
